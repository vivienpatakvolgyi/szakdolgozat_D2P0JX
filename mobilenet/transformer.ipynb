{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libray to handle status bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import libray to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# importing deep learning library\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (240, 240, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_extract_y.pkl', 'rb') as f:\n",
    "    train_y = pickle.load(f)\n",
    "\n",
    "with open('./val_extract_y.pkl', 'rb') as f:\n",
    "    test_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(group, amount):\n",
    "    for i in range(amount):\n",
    "        with open(f'./{group}_extract{i}.pkl', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        X = X.reshape(X.shape[0], 64, X.shape[-1])\n",
    "\n",
    "        yield X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X =list(add('train', 17))\n",
    "test_X = list(add('test', 2))\n",
    "val_X = list(add('val', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_test = [3546, 3413]\n",
    "frames_val = [4832, 4326]\n",
    "frames_train = [6388, 3620, 3000, 2938, 3220, 3908, 1645, 4692, 5736, 5064, 4720, 2916, 2597, 4739, 3653, 3612, 4678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 64\n",
    "NUM_FEATURES = 2048\n",
    "IMG_SIZE = 240\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.3\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=tf.nn.gelu), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def dataGEN(train_X, train_y): \\n    while True:\\n        for i in range(len(train_X)):\\n            train_X_a = train_X[i]\\n            train_y_a = train_y[i]\\n            N=1000\\n            train_X_subs = [train_X_a[n:n+N] for n in range(0, len(train_X_a), N-500)]\\n            train_y_subs = [train_y_a[n:n+N] for n in range(0, len(train_y_a), N-500)]\\n            for k in range(len(train_X_subs[i])):\\n                yield (train_X_subs[k], train_y_subs[k])'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def dataGEN(train_X, train_y): \n",
    "    while True:\n",
    "        for i in range(len(train_X)):\n",
    "            train_X_a = train_X[i]\n",
    "            train_y_a = train_y[i]\n",
    "            N=1000\n",
    "            train_X_subs = [train_X_a[n:n+N] for n in range(0, len(train_X_a), N-500)]\n",
    "            train_y_subs = [train_y_a[n:n+N] for n in range(0, len(train_y_a), N-500)]\n",
    "            for k in range(len(train_X_subs[i])):\n",
    "                yield (train_X_subs[k], train_y_subs[k])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_compiled_model():\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    embed_dim = NUM_FEATURES\n",
    "    dense_dim = 8\n",
    "    num_heads = 1\n",
    "    classes = 7\n",
    "\n",
    "    inputs = keras.Input(shape=(None, None))\n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(inputs)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    " \n",
    "def run_experiment():\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        \"video_classifier.h5\", save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    model = get_compiled_model()\n",
    "    for i in range(0,17,1):\n",
    "        with open(f'./train_extract{i}.pkl', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        X = X.reshape(X.shape[0], 64, X.shape[-1])\n",
    "        train_y_a = train_y[i]\n",
    "        N=1000\n",
    "        train_X_subs = [X[n:n+N] for n in range(0, len(X), N-100)]\n",
    "        train_y_subs = [train_y_a[n:n+N] for n in range(0, len(train_y_a), N-100)]\n",
    "        for k in range(len(train_X_subs)):\n",
    "            for j in range(2):\n",
    "                test_X_a = test_X[j]\n",
    "                test_y_a = test_y[j]\n",
    "                N=1000\n",
    "                test_X_subs = [test_X_a[n:n+N] for n in range(0, len(test_X_a), N-100)]\n",
    "                test_y_subs = [test_y_a[n:n+N] for n in range(0, len(test_y_a), N-100)]\n",
    "                for l in range(len(test_X_subs)):\n",
    "                    model.fit(\n",
    "                        np.array(train_X_subs[k]),\n",
    "                        np.array(train_y_subs[k]),\n",
    "                        epochs=1,\n",
    "                        callbacks=[checkpoint],\n",
    "                        validation_data = (test_X_subs[l], test_y_subs[l])\n",
    "                    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 6 0\n",
      "test 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 2.6828 - accuracy: 0.6230\n",
      "Epoch 1: val_loss improved from inf to 3.76669, saving model to video_classifier1.h5\n",
      "32/32 [==============================] - 18s 480ms/step - loss: 2.6828 - accuracy: 0.6230 - val_loss: 3.7667 - val_accuracy: 0.1820\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9060\n",
      "Epoch 1: val_loss did not improve from 3.76669\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 0.2363 - accuracy: 0.9060 - val_loss: 7.5043 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9330\n",
      "Epoch 1: val_loss did not improve from 3.76669\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 0.1782 - accuracy: 0.9330 - val_loss: 9.8792 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9610\n",
      "Epoch 1: val_loss did not improve from 3.76669\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 0.1174 - accuracy: 0.9610 - val_loss: 8.9865 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.9680\n",
      "Epoch 1: val_loss improved from 3.76669 to 2.02548, saving model to video_classifier1.h5\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 0.1019 - accuracy: 0.9680 - val_loss: 2.0255 - val_accuracy: 0.5490\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9680\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 14s 441ms/step - loss: 0.1045 - accuracy: 0.9680 - val_loss: 5.6728 - val_accuracy: 0.1300\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9680\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 17s 510ms/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 11.1255 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9810\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 14s 449ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 9.7457 - val_accuracy: 0.0000e+00\n",
      "train 6 1\n",
      "test 0 0\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.6336\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 12s 493ms/step - loss: 1.5431 - accuracy: 0.6336 - val_loss: 3.3412 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.8215\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 12s 485ms/step - loss: 0.4817 - accuracy: 0.8215 - val_loss: 5.1876 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8631\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 11s 467ms/step - loss: 0.3737 - accuracy: 0.8631 - val_loss: 4.7813 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.8752\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 11s 445ms/step - loss: 0.3150 - accuracy: 0.8752 - val_loss: 5.3214 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9181\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 11s 464ms/step - loss: 0.2220 - accuracy: 0.9181 - val_loss: 2.8287 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9168\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 11s 448ms/step - loss: 0.2089 - accuracy: 0.9168 - val_loss: 3.9196 - val_accuracy: 0.0010\n",
      "test 1 2\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9302\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 12s 487ms/step - loss: 0.1886 - accuracy: 0.9302 - val_loss: 5.0868 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9235\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "24/24 [==============================] - 10s 409ms/step - loss: 0.1990 - accuracy: 0.9235 - val_loss: 4.3884 - val_accuracy: 0.0000e+00\n",
      "train 7 0\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8440\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.3970 - accuracy: 0.8440 - val_loss: 2.7920 - val_accuracy: 0.1800\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9180\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.2022 - accuracy: 0.9180 - val_loss: 5.1408 - val_accuracy: 0.0030\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9450\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.1624 - accuracy: 0.9450 - val_loss: 7.0760 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9500\n",
      "Epoch 1: val_loss did not improve from 2.02548\n",
      "32/32 [==============================] - 13s 396ms/step - loss: 0.1439 - accuracy: 0.9500 - val_loss: 7.2923 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9530\n",
      "Epoch 1: val_loss improved from 2.02548 to 2.02041, saving model to video_classifier1.h5\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.1188 - accuracy: 0.9530 - val_loss: 2.0204 - val_accuracy: 0.5500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9650\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 0.0870 - accuracy: 0.9650 - val_loss: 5.4490 - val_accuracy: 0.0010\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9750\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 0.0700 - accuracy: 0.9750 - val_loss: 8.4863 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9760\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 12s 387ms/step - loss: 0.0751 - accuracy: 0.9760 - val_loss: 7.7731 - val_accuracy: 0.0000e+00\n",
      "train 7 1\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8940\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 0.4501 - accuracy: 0.8940 - val_loss: 3.3266 - val_accuracy: 0.1800\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9560\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.1200 - accuracy: 0.9560 - val_loss: 2.7581 - val_accuracy: 0.0150\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9710\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.0758 - accuracy: 0.9710 - val_loss: 5.1112 - val_accuracy: 0.0020\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9680\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.0687 - accuracy: 0.9680 - val_loss: 5.1351 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9830\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 422ms/step - loss: 0.0554 - accuracy: 0.9830 - val_loss: 2.6370 - val_accuracy: 0.0050\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9780\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 0.0557 - accuracy: 0.9780 - val_loss: 2.4169 - val_accuracy: 0.3560\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 5.0251 - val_accuracy: 0.0660\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9830\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 4.2771 - val_accuracy: 0.0000e+00\n",
      "train 7 2\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9469 - accuracy: 0.7810\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 0.9469 - accuracy: 0.7810 - val_loss: 7.6178 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9210\n",
      "Epoch 1: val_loss did not improve from 2.02041\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.2050 - accuracy: 0.9210 - val_loss: 9.4513 - val_accuracy: 0.0840\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9410\n",
      "Epoch 1: val_loss improved from 2.02041 to 1.97789, saving model to video_classifier1.h5\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1819 - accuracy: 0.9410 - val_loss: 1.9779 - val_accuracy: 0.1520\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9450\n",
      "Epoch 1: val_loss did not improve from 1.97789\n",
      "32/32 [==============================] - 12s 391ms/step - loss: 0.1411 - accuracy: 0.9450 - val_loss: 3.6348 - val_accuracy: 0.1265\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9510\n",
      "Epoch 1: val_loss did not improve from 1.97789\n",
      "32/32 [==============================] - 14s 434ms/step - loss: 0.1275 - accuracy: 0.9510 - val_loss: 7.0524 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9580\n",
      "Epoch 1: val_loss did not improve from 1.97789\n",
      "32/32 [==============================] - 16s 472ms/step - loss: 0.1150 - accuracy: 0.9580 - val_loss: 10.4970 - val_accuracy: 0.0020\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9610\n",
      "Epoch 1: val_loss did not improve from 1.97789\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.0824 - accuracy: 0.9610 - val_loss: 3.2639 - val_accuracy: 0.1250\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9670\n",
      "Epoch 1: val_loss improved from 1.97789 to 0.71014, saving model to video_classifier1.h5\n",
      "32/32 [==============================] - 12s 388ms/step - loss: 0.0874 - accuracy: 0.9670 - val_loss: 0.7101 - val_accuracy: 0.8079\n",
      "train 7 3\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8970\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 0.3536 - accuracy: 0.8970 - val_loss: 9.9733 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.9390\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 436ms/step - loss: 0.1670 - accuracy: 0.9390 - val_loss: 12.8962 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9410\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 0.1463 - accuracy: 0.9410 - val_loss: 5.7003 - val_accuracy: 0.1400\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9470\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 390ms/step - loss: 0.1320 - accuracy: 0.9470 - val_loss: 4.3215 - val_accuracy: 0.1277\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9560\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.1189 - accuracy: 0.9560 - val_loss: 9.3636 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9580\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 15s 457ms/step - loss: 0.0946 - accuracy: 0.9580 - val_loss: 11.5313 - val_accuracy: 0.0000e+00\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9610\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 0.1007 - accuracy: 0.9610 - val_loss: 4.6670 - val_accuracy: 0.1210\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9690\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 382ms/step - loss: 0.0780 - accuracy: 0.9690 - val_loss: 0.7336 - val_accuracy: 0.8233\n",
      "train 7 4\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9280\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 0.2315 - accuracy: 0.9280 - val_loss: 11.4319 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9440\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 426ms/step - loss: 0.1450 - accuracy: 0.9440 - val_loss: 12.2650 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9470\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.1414 - accuracy: 0.9470 - val_loss: 5.6287 - val_accuracy: 0.1400\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9600\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 0.0994 - accuracy: 0.9600 - val_loss: 4.2782 - val_accuracy: 0.1265\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9670\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 0.0832 - accuracy: 0.9670 - val_loss: 9.9350 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9700\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 396ms/step - loss: 0.0723 - accuracy: 0.9700 - val_loss: 12.8359 - val_accuracy: 0.0000e+00\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9670\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 0.0748 - accuracy: 0.9670 - val_loss: 5.7285 - val_accuracy: 0.1200\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9780\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 377ms/step - loss: 0.0644 - accuracy: 0.9780 - val_loss: 0.9102 - val_accuracy: 0.8317\n",
      "train 7 5\n",
      "test 0 0\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9844\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 999ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 12.9823 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 14.8236 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "6/6 [==============================] - ETA: 0s - loss: 5.4927e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 6s 1s/step - loss: 5.4927e-04 - accuracy: 1.0000 - val_loss: 10.7471 - val_accuracy: 0.1400\n",
      "test 0 3\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.4604e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 858ms/step - loss: 3.4604e-04 - accuracy: 1.0000 - val_loss: 11.5772 - val_accuracy: 0.1265\n",
      "test 1 0\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.7603e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 1s/step - loss: 2.7603e-05 - accuracy: 1.0000 - val_loss: 14.7950 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.9132e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 957ms/step - loss: 1.9132e-05 - accuracy: 1.0000 - val_loss: 16.2702 - val_accuracy: 0.0000e+00\n",
      "test 1 2\n",
      "6/6 [==============================] - ETA: 0s - loss: 2.2249e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 6s 1s/step - loss: 2.2249e-05 - accuracy: 1.0000 - val_loss: 12.5547 - val_accuracy: 0.1200\n",
      "test 1 3\n",
      "6/6 [==============================] - ETA: 0s - loss: 8.3913e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "6/6 [==============================] - 5s 937ms/step - loss: 8.3913e-05 - accuracy: 1.0000 - val_loss: 2.3470 - val_accuracy: 0.8317\n",
      "train 8 0\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.0793 - accuracy: 0.7780\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 16s 489ms/step - loss: 1.0793 - accuracy: 0.7780 - val_loss: 5.4439 - val_accuracy: 0.1800\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9380\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 440ms/step - loss: 0.1714 - accuracy: 0.9380 - val_loss: 14.5121 - val_accuracy: 0.0000e+00\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9470\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.1432 - accuracy: 0.9470 - val_loss: 23.0182 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9480\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.1465 - accuracy: 0.9480 - val_loss: 23.5222 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9510\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 439ms/step - loss: 0.1331 - accuracy: 0.9510 - val_loss: 1.1194 - val_accuracy: 0.5500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9670\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 0.0976 - accuracy: 0.9670 - val_loss: 9.7729 - val_accuracy: 0.0000e+00\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9630\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 0.1022 - accuracy: 0.9630 - val_loss: 20.9402 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9670\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 390ms/step - loss: 0.0757 - accuracy: 0.9670 - val_loss: 30.6430 - val_accuracy: 0.0000e+00\n",
      "train 8 1\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9960\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 0.0099 - accuracy: 0.9960 - val_loss: 2.3613 - val_accuracy: 0.7470\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.8876e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.8876e-04 - accuracy: 1.0000 - val_loss: 12.1031 - val_accuracy: 0.4130\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9990\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 393ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 21.8306 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.4437e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 391ms/step - loss: 1.4437e-05 - accuracy: 1.0000 - val_loss: 22.5513 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1538e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 3.1538e-05 - accuracy: 1.0000 - val_loss: 3.0111 - val_accuracy: 0.4500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4915e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 5.4915e-05 - accuracy: 1.0000 - val_loss: 9.0549 - val_accuracy: 0.6000\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.2500e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 2.2500e-05 - accuracy: 1.0000 - val_loss: 21.8978 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2682e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 378ms/step - loss: 3.2682e-05 - accuracy: 1.0000 - val_loss: 31.6059 - val_accuracy: 0.0000e+00\n",
      "train 8 2\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.7509e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 393ms/step - loss: 1.7509e-05 - accuracy: 1.0000 - val_loss: 2.7094 - val_accuracy: 0.7470\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.3446e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.3446e-05 - accuracy: 1.0000 - val_loss: 12.3504 - val_accuracy: 0.4130\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.7306e-06 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 2.7306e-06 - accuracy: 1.0000 - val_loss: 21.9338 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.6833e-07 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 388ms/step - loss: 6.6833e-07 - accuracy: 1.0000 - val_loss: 22.6328 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.3967e-06 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 6.3967e-06 - accuracy: 1.0000 - val_loss: 3.1128 - val_accuracy: 0.4500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.3923e-05 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 413ms/step - loss: 1.3923e-05 - accuracy: 1.0000 - val_loss: 9.0782 - val_accuracy: 0.6000\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1182e-06 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 395ms/step - loss: 3.1182e-06 - accuracy: 1.0000 - val_loss: 21.9419 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.5035e-07 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 377ms/step - loss: 6.5035e-07 - accuracy: 1.0000 - val_loss: 31.6381 - val_accuracy: 0.0000e+00\n",
      "train 8 3\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2849 - accuracy: 0.5970\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 4.2849 - accuracy: 0.5970 - val_loss: 2.4581 - val_accuracy: 0.0730\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8190\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.5160 - accuracy: 0.8190 - val_loss: 2.7431 - val_accuracy: 0.4130\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.8640\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.3097 - accuracy: 0.8640 - val_loss: 9.2473 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.8970\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 14s 422ms/step - loss: 0.2592 - accuracy: 0.8970 - val_loss: 8.9753 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.8990\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 407ms/step - loss: 0.2354 - accuracy: 0.8990 - val_loss: 4.7604 - val_accuracy: 0.4490\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9230\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 0.1971 - accuracy: 0.9230 - val_loss: 1.0672 - val_accuracy: 0.6000\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9330\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 0.1688 - accuracy: 0.9330 - val_loss: 10.0292 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9360\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 371ms/step - loss: 0.1550 - accuracy: 0.9360 - val_loss: 12.6281 - val_accuracy: 0.0000e+00\n",
      "train 8 4\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.7970\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.7461 - accuracy: 0.7970 - val_loss: 3.2288 - val_accuracy: 0.0000e+00\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9390\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 390ms/step - loss: 0.1203 - accuracy: 0.9390 - val_loss: 1.5826 - val_accuracy: 0.2200\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9650\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 0.0926 - accuracy: 0.9650 - val_loss: 6.0975 - val_accuracy: 0.3000\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9670\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 385ms/step - loss: 0.0825 - accuracy: 0.9670 - val_loss: 8.0967 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9740\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 0.0688 - accuracy: 0.9740 - val_loss: 4.0916 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9840\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.0455 - accuracy: 0.9840 - val_loss: 1.7173 - val_accuracy: 0.3580\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9880\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 0.0468 - accuracy: 0.9880 - val_loss: 6.5151 - val_accuracy: 0.0610\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9840\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 373ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 10.4210 - val_accuracy: 0.0000e+00\n",
      "train 8 5\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7884 - accuracy: 0.8220\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 386ms/step - loss: 0.7884 - accuracy: 0.8220 - val_loss: 2.2541 - val_accuracy: 0.0020\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9610\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 397ms/step - loss: 0.1080 - accuracy: 0.9610 - val_loss: 4.4482 - val_accuracy: 0.0030\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9680\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 0.0666 - accuracy: 0.9680 - val_loss: 3.4191 - val_accuracy: 0.1400\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9760\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 383ms/step - loss: 0.0618 - accuracy: 0.9760 - val_loss: 3.1970 - val_accuracy: 0.1265\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9850\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 0.0465 - accuracy: 0.9850 - val_loss: 3.0369 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9840\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 419ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 3.5299 - val_accuracy: 0.0010\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9850\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 3.6400 - val_accuracy: 0.1220\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9870\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "32/32 [==============================] - 12s 393ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.7290 - val_accuracy: 0.8331\n",
      "train 8 6\n",
      "test 0 0\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8750\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 0.4620 - accuracy: 0.8750 - val_loss: 2.5594 - val_accuracy: 0.0010\n",
      "test 0 1\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9196\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 6s 616ms/step - loss: 0.2059 - accuracy: 0.9196 - val_loss: 3.9978 - val_accuracy: 0.0040\n",
      "test 0 2\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9405\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 7s 638ms/step - loss: 0.1757 - accuracy: 0.9405 - val_loss: 2.2724 - val_accuracy: 0.5600\n",
      "test 0 3\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9464\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 6s 568ms/step - loss: 0.1272 - accuracy: 0.9464 - val_loss: 1.0696 - val_accuracy: 0.1253\n",
      "test 1 0\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9583\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 6s 618ms/step - loss: 0.0999 - accuracy: 0.9583 - val_loss: 2.9271 - val_accuracy: 0.0000e+00\n",
      "test 1 1\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9673\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 6s 619ms/step - loss: 0.0805 - accuracy: 0.9673 - val_loss: 3.7121 - val_accuracy: 0.0010\n",
      "test 1 2\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9732\n",
      "Epoch 1: val_loss did not improve from 0.71014\n",
      "11/11 [==============================] - 7s 634ms/step - loss: 0.0718 - accuracy: 0.9732 - val_loss: 2.5839 - val_accuracy: 0.1200\n",
      "test 1 3\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9762\n",
      "Epoch 1: val_loss improved from 0.71014 to 0.58005, saving model to video_classifier1.h5\n",
      "11/11 [==============================] - 6s 531ms/step - loss: 0.0561 - accuracy: 0.9762 - val_loss: 0.5800 - val_accuracy: 0.8317\n",
      "train 9 0\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.8510\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 0.8913 - accuracy: 0.8510 - val_loss: 2.0884 - val_accuracy: 0.7470\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9680\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 0.1008 - accuracy: 0.9680 - val_loss: 2.9249 - val_accuracy: 0.4130\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9760\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 0.0677 - accuracy: 0.9760 - val_loss: 14.8756 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9820\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 0.0555 - accuracy: 0.9820 - val_loss: 17.6616 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9890\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 4.7501 - val_accuracy: 0.4500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9880\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 395ms/step - loss: 0.0351 - accuracy: 0.9880 - val_loss: 1.9160 - val_accuracy: 0.6000\n",
      "test 1 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9850\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 0.0409 - accuracy: 0.9850 - val_loss: 14.9204 - val_accuracy: 0.0000e+00\n",
      "test 1 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9900\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 12s 378ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 16.7038 - val_accuracy: 0.0000e+00\n",
      "train 9 1\n",
      "test 0 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1309 - val_accuracy: 0.7470\n",
      "test 0 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 8.8392e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 12s 389ms/step - loss: 8.8392e-04 - accuracy: 1.0000 - val_loss: 4.4593 - val_accuracy: 0.4130\n",
      "test 0 2\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7250e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 14s 447ms/step - loss: 4.7250e-04 - accuracy: 1.0000 - val_loss: 16.5279 - val_accuracy: 0.0000e+00\n",
      "test 0 3\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8338e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 12s 390ms/step - loss: 3.8338e-04 - accuracy: 1.0000 - val_loss: 19.1501 - val_accuracy: 0.0000e+00\n",
      "test 1 0\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2867e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 3.2867e-04 - accuracy: 1.0000 - val_loss: 5.7171 - val_accuracy: 0.4500\n",
      "test 1 1\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8679e-04 - accuracy: 1.0000\n",
      "Epoch 1: val_loss did not improve from 0.58005\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 2.8679e-04 - accuracy: 1.0000 - val_loss: 2.9450 - val_accuracy: 0.6000\n",
      "test 1 2\n",
      "18/32 [===============>..............] - ETA: 4s - loss: 2.1831e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\tranny.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trained_model \u001b[39m=\u001b[39m run_experiment()\n",
      "\u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\tranny.ipynb Cell 28\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m             \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test_X_subs)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                 \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, j, l)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                 model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m                     np\u001b[39m.\u001b[39;49marray(train_X_subs[k]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                     np\u001b[39m.\u001b[39;49marray(train_y_subs[k]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[checkpoint],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                     validation_data \u001b[39m=\u001b[39;49m (test_X_subs[l], test_y_subs[l])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                 )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X35sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kirtkels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 3 layers, found 104 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\tranny.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ready_model \u001b[39m=\u001b[39m get_compiled_model()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Via/Documents/SZD_code/tranny.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ready_model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39mmobilenet.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Via\\Documents\\SZD_code\\Lib\\site-packages\\keras\\src\\saving\\legacy\\hdf5_format.py:816\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    814\u001b[0m layer_names \u001b[39m=\u001b[39m filtered_layer_names\n\u001b[0;32m    815\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(layer_names) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(filtered_layers):\n\u001b[1;32m--> 816\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLayer count mismatch when loading weights from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    818\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel expected \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(filtered_layers)\u001b[39m}\u001b[39;00m\u001b[39m layers, found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    819\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(layer_names)\u001b[39m}\u001b[39;00m\u001b[39m saved layers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    820\u001b[0m     )\n\u001b[0;32m    822\u001b[0m \u001b[39m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 3 layers, found 104 saved layers."
     ]
    }
   ],
   "source": [
    "ready_model = get_compiled_model()\n",
    "ready_model.load_weights('video_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 31s 224ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = ready_model.predict(val_X[0])\n",
    "y_pred2 = ready_model.predict(val_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mnet_pred_1.txt', 'w') as f:  # open a text file\n",
    "    for i in range(y_pred1.shape[0]):\n",
    "        f.writelines(str(f\"{i}\\t{np.argmax(y_pred1[i])}\\n\")) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mnet_pred_2.txt', 'w') as f:  # open a text file\n",
    "    for i in range(y_pred2.shape[0]):\n",
    "        f.writelines(str(f\"{i}\\t{np.argmax(y_pred2[i])}\\n\")) # serialize the list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SZD_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
